{"componentChunkName":"component---src-pages-guides-continuous-integration-index-mdx","path":"/guides/continuous-integration/","webpackCompilationHash":"1a616bbb4bee56c2a30a","result":{"pageContext":{"isCreatedByStatefulCreatePages":true,"frontmatter":{"title":"Continuous Integration","description":"This guide will explain how to use Jenkins to manage your Continuous Integration process"},"relativePagePath":"/guides/continuous-integration/index.mdx","titleType":"page","MdxNode":{"id":"7cdcc840-cfdf-511e-8aca-7f3e421bacef","children":[],"parent":"f1c385fd-7184-5cf3-b56f-1f129ed3ce98","internal":{"content":"---\ntitle: Continuous Integration\ndescription: This guide will explain how to use Jenkins to manage your Continuous Integration process\n---\n\nContinous integration is a software development technique where software is built regularly by a team in an automated fashion.\nThis quote helps explain it:\n\n> Continuous Integration is a software development practice where members of a team integrate their work frequently,\n> usually each person integrates at least daily - leading to multiple integrations per day.\n> Each integration is verified by an automated build (including test) to\n> detect integration errors as quickly as possible. Many teams find that this approach leads to significantly\n> reduced integration problems and allows a team to develop cohesive software more rapidly\n> <cite>– Martin Fowler</cite>\n\n## What is Jenkins\n\nJenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.\nIt is a perfect tool for helping managing continuous integration tasks for a wide range of software component's.\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.\n\nA continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines \"as code\". The definition of a Jenkins Pipeline is typically written into a text file (called a [Jenkinsfile](https://jenkins.io/doc/pipeline/tour/hello-world/)) which in turn is checked into a project’s source control repository.\n\n\n### Pipelines\n\n\n\n### Stages\n\nYou can see from either the vanilla Jenkins pipelines view of the Application Console pipelines view, each template offers a number of pipeline stages. The stages have been configured to be work from the defined `secrets` and `config maps` that have been defined in the Development cluster setup.\n\nThe `Jenkinsfile` is consistent between registration with OpenShift or IKS. The `Dockerfile` has been optimized for `UBI` images, this means the docker images when deployed can run on both OpenShift and IKS.\n\nThe following gives a description of what each stage in the pipeline does. The *Optional* stages can be deleted or ignored if the tool support it is not installed. These stages represent a typical production pipeline flow for a Cloud Native application.\n\n- **Setup** clones the code into the pipeline\n- **Build** runs the build commands for the code\n- **Test**\tvalidates the unit tests for the code\n- **Publish pacts**\t(*optional*) publishes any pact contracts that have been defined\n- **Verify pact** (*optional*) verifies the pact contracts\n- **Sonar scan** (*optional*) runs a sonar code scan of the source code and publishes the results to SonarQube\n- **Verify environment** Validates the OpenShift or IKS environment configuration is valid\n- **Build image** Builds the code into a Docker images and stores it in the IBM Cloud Image registry\n- **Deploy to DEV env**\tDeploys the Docker image tagged version to `dev` namespace using Helm Chart\n- **Package Helm Chart** (*optional*) Stores the tagged version of the Helm chart into Artifactory\n- **Health Check** Validates the Health Endpoint of the deployed application\n\n\n## Deploying Code into Pipelines\n\nNow you have a working development environment that includes Jenkins on the IBM Public Cloud. You can now start working with code to deploy into your cluster using Jenkins pipelines. The following instructions help describe this process.\n\nYou can click on the `Starter Kit Templates` tab on the Development Cluster Dashboard and follow the instructions for provisioning a new microservice into your development cluster. You can easily create an microservice by using the github templates listed below:\n\n* [12 UI Patterns with React and Node.js](https://github.com/ibm-garage-cloud/template-node-react)\n* [TypeScript Microservice or BFF with Node.js](https://github.com/ibm-garage-cloud/template-node-typescript)\n* [GraphQL BFF with Node.js](https://github.com/ibm-garage-cloud/template-graphql-typescript)\n* [Spring Boot Java Microservice](https://github.com/ibm-garage-cloud/template-java-spring)\n\nClick on the `Use this template` button to create a repo in your git organisation. Then follow the pipeline registration instructions below: \n\n- You will need to be logged into the OpenShift Console or IKS clusters on the command line. \n\n- You will also need a [Personal Access Token](https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line) from your git organistaion.\n\nThe following steps will enable you to register the template with OpenShift or IKS instance of Jenkins Pipelines.\n\n```bash\ngit clone <generated start kit template>\ncd <generated start kit template>\nvi package.json ! rename the template\ngit add .\ngit commit -m \"Rename project\"\ngit push\n```\n\nThe following steps will help you create a pipeline with Jenkins using the `CLI`.\n\n```bash\nigc pipeline \n? Please provide the username for https://github.com/mjperrins/hello-world-bff.git: mperrins\n? Please provide your password/personal access token: [hidden]\n? Please provide the branch the pipeline should use: master\nCreating git secret\nCopying 'ibmcloud-apikey' secret to dev\nRegistering pipeline\n? The build pipeline (mjperrins.hello-world-bff) already exists. Do you want to update it? (Y/n)\n```\n\nThe pipeline will be created in the `dev` namespace in OpenShift and `tools` name space on IKS . The registration will copy the necessary secrets required to run the pipeline and expose the secrets to the `Jenkinsfile`. The app docker image will be stored in the IBM Container Registry and deployed into the `dev` name space. \n\n\nThis is screen shot of a Jenkins pipeline, you can access this view from the Developer Dashboard.\n\n![Jenkins Pipelines View](images/pipelines.png)\n\nThis is a screen shot of the Build Pipeline in OpenShift. You can access this from the `Application Console` and selecting `Builds->Pipelines` from the menu.\n\n![OpenShift Pipelines View](images/ospipelines.png)\n\n\n### Ingress URLs or testing\n\nIf you want to get easy access to your application routes or ingress end points for your apps run the following command. All the `igc` commands run the same on IKS and OpenShift.\n```bash\nigc ingress -n dev\n```\nThis will list out the applications URLs that have been deployed.\n\n```bash\nHost(s):\n[\n  'http://stock-bff-dev.showcase-dev-oswdc06-cl.us-east.containers.appdomain.cloud',\n  'http://stock-service-dev.showcase-dev-oswdc06-cl.us-east.containers.appdomain.cloud',\n  'http://stock-ui-dev.showcase-dev-oswdc06-cl.us-east.containers.appdomain.cloud',\n]\n```\n\nOnce you become familiar with deploying code into OpenShift or IKS, read up about how you can manage code deployment with `Continuous Deployment` with `Artiactory` and `ArgoCD`\n\n- [Artiact Storage with Artifactory](./ARTIFACTORY.md)\n- [Continuous Deployment with ArgoCD](./ARGOCD.md)\n\nYou can use the [Argo CD Template](https://github.com/ibm-garage-cloud/template-argocd-test) to help define a deployment configuration for `test` and `staging` namespaces.\n\n\n\n","type":"Mdx","contentDigest":"5d306aca2a9aaa0ca23ba90552f209ac","counter":208,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Continuous Integration","description":"This guide will explain how to use Jenkins to manage your Continuous Integration process"},"exports":{},"rawBody":"---\ntitle: Continuous Integration\ndescription: This guide will explain how to use Jenkins to manage your Continuous Integration process\n---\n\nContinous integration is a software development technique where software is built regularly by a team in an automated fashion.\nThis quote helps explain it:\n\n> Continuous Integration is a software development practice where members of a team integrate their work frequently,\n> usually each person integrates at least daily - leading to multiple integrations per day.\n> Each integration is verified by an automated build (including test) to\n> detect integration errors as quickly as possible. Many teams find that this approach leads to significantly\n> reduced integration problems and allows a team to develop cohesive software more rapidly\n> <cite>– Martin Fowler</cite>\n\n## What is Jenkins\n\nJenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.\nIt is a perfect tool for helping managing continuous integration tasks for a wide range of software component's.\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.\n\nA continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines \"as code\". The definition of a Jenkins Pipeline is typically written into a text file (called a [Jenkinsfile](https://jenkins.io/doc/pipeline/tour/hello-world/)) which in turn is checked into a project’s source control repository.\n\n\n### Pipelines\n\n\n\n### Stages\n\nYou can see from either the vanilla Jenkins pipelines view of the Application Console pipelines view, each template offers a number of pipeline stages. The stages have been configured to be work from the defined `secrets` and `config maps` that have been defined in the Development cluster setup.\n\nThe `Jenkinsfile` is consistent between registration with OpenShift or IKS. The `Dockerfile` has been optimized for `UBI` images, this means the docker images when deployed can run on both OpenShift and IKS.\n\nThe following gives a description of what each stage in the pipeline does. The *Optional* stages can be deleted or ignored if the tool support it is not installed. These stages represent a typical production pipeline flow for a Cloud Native application.\n\n- **Setup** clones the code into the pipeline\n- **Build** runs the build commands for the code\n- **Test**\tvalidates the unit tests for the code\n- **Publish pacts**\t(*optional*) publishes any pact contracts that have been defined\n- **Verify pact** (*optional*) verifies the pact contracts\n- **Sonar scan** (*optional*) runs a sonar code scan of the source code and publishes the results to SonarQube\n- **Verify environment** Validates the OpenShift or IKS environment configuration is valid\n- **Build image** Builds the code into a Docker images and stores it in the IBM Cloud Image registry\n- **Deploy to DEV env**\tDeploys the Docker image tagged version to `dev` namespace using Helm Chart\n- **Package Helm Chart** (*optional*) Stores the tagged version of the Helm chart into Artifactory\n- **Health Check** Validates the Health Endpoint of the deployed application\n\n\n## Deploying Code into Pipelines\n\nNow you have a working development environment that includes Jenkins on the IBM Public Cloud. You can now start working with code to deploy into your cluster using Jenkins pipelines. The following instructions help describe this process.\n\nYou can click on the `Starter Kit Templates` tab on the Development Cluster Dashboard and follow the instructions for provisioning a new microservice into your development cluster. You can easily create an microservice by using the github templates listed below:\n\n* [12 UI Patterns with React and Node.js](https://github.com/ibm-garage-cloud/template-node-react)\n* [TypeScript Microservice or BFF with Node.js](https://github.com/ibm-garage-cloud/template-node-typescript)\n* [GraphQL BFF with Node.js](https://github.com/ibm-garage-cloud/template-graphql-typescript)\n* [Spring Boot Java Microservice](https://github.com/ibm-garage-cloud/template-java-spring)\n\nClick on the `Use this template` button to create a repo in your git organisation. Then follow the pipeline registration instructions below: \n\n- You will need to be logged into the OpenShift Console or IKS clusters on the command line. \n\n- You will also need a [Personal Access Token](https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line) from your git organistaion.\n\nThe following steps will enable you to register the template with OpenShift or IKS instance of Jenkins Pipelines.\n\n```bash\ngit clone <generated start kit template>\ncd <generated start kit template>\nvi package.json ! rename the template\ngit add .\ngit commit -m \"Rename project\"\ngit push\n```\n\nThe following steps will help you create a pipeline with Jenkins using the `CLI`.\n\n```bash\nigc pipeline \n? Please provide the username for https://github.com/mjperrins/hello-world-bff.git: mperrins\n? Please provide your password/personal access token: [hidden]\n? Please provide the branch the pipeline should use: master\nCreating git secret\nCopying 'ibmcloud-apikey' secret to dev\nRegistering pipeline\n? The build pipeline (mjperrins.hello-world-bff) already exists. Do you want to update it? (Y/n)\n```\n\nThe pipeline will be created in the `dev` namespace in OpenShift and `tools` name space on IKS . The registration will copy the necessary secrets required to run the pipeline and expose the secrets to the `Jenkinsfile`. The app docker image will be stored in the IBM Container Registry and deployed into the `dev` name space. \n\n\nThis is screen shot of a Jenkins pipeline, you can access this view from the Developer Dashboard.\n\n![Jenkins Pipelines View](images/pipelines.png)\n\nThis is a screen shot of the Build Pipeline in OpenShift. You can access this from the `Application Console` and selecting `Builds->Pipelines` from the menu.\n\n![OpenShift Pipelines View](images/ospipelines.png)\n\n\n### Ingress URLs or testing\n\nIf you want to get easy access to your application routes or ingress end points for your apps run the following command. All the `igc` commands run the same on IKS and OpenShift.\n```bash\nigc ingress -n dev\n```\nThis will list out the applications URLs that have been deployed.\n\n```bash\nHost(s):\n[\n  'http://stock-bff-dev.showcase-dev-oswdc06-cl.us-east.containers.appdomain.cloud',\n  'http://stock-service-dev.showcase-dev-oswdc06-cl.us-east.containers.appdomain.cloud',\n  'http://stock-ui-dev.showcase-dev-oswdc06-cl.us-east.containers.appdomain.cloud',\n]\n```\n\nOnce you become familiar with deploying code into OpenShift or IKS, read up about how you can manage code deployment with `Continuous Deployment` with `Artiactory` and `ArgoCD`\n\n- [Artiact Storage with Artifactory](./ARTIFACTORY.md)\n- [Continuous Deployment with ArgoCD](./ARGOCD.md)\n\nYou can use the [Argo CD Template](https://github.com/ibm-garage-cloud/template-argocd-test) to help define a deployment configuration for `test` and `staging` namespaces.\n\n\n\n","fileAbsolutePath":"/Users/seansund/ws/catalyst/garage-developer-guide/src/pages/guides/continuous-integration/index.mdx"}}}}