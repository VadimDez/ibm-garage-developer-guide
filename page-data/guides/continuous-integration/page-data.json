{"componentChunkName":"component---src-pages-guides-continuous-integration-index-mdx","path":"/guides/continuous-integration/","result":{"pageContext":{"isCreatedByStatefulCreatePages":true,"frontmatter":{"title":"Continuous Integration with Jenkins","description":"This guide will explain how to use Jenkins to manage your Continuous Integration process"},"relativePagePath":"/guides/continuous-integration/index.mdx","titleType":"page","MdxNode":{"id":"f11f403f-b724-5764-84b8-3f09fdd16c60","children":[],"parent":"96d47704-6c1d-56d5-88d0-f2d6a16a2ecf","internal":{"content":"---\ntitle: Continuous Integration with Jenkins\ndescription: This guide will explain how to use Jenkins to manage your Continuous Integration process\n---\n\nContinous integration is a software development technique where software is built regularly by a team in an automated fashion.\nThis quote helps explain it:\n\n> Continuous Integration is a software development practice where members of a team integrate their work frequently,\n> usually each person integrates at least daily - leading to multiple integrations per day.\n> Each integration is verified by an automated build (including test) to\n> detect integration errors as quickly as possible. Many teams find that this approach leads to significantly\n> reduced integration problems and allows a team to develop cohesive software more rapidly\n> <cite>– Martin Fowler</cite>\n\n## What is Jenkins\n\nJenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.\nIt is a perfect tool for helping managing continuous integration tasks for a wide range of software component's.\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.\n\nA continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines \"as code\". The definition of a Jenkins Pipeline is typically written into a text file (called a [Jenkinsfile](https://jenkins.io/doc/pipeline/tour/hello-world/)) which in turn is checked into a project’s source control repository.\n\n\n\n### Pipelines\n\nPipelines offer a set of stages or steps that can be chained together to allow a level of software\nautomation. This automation can be tailored to the specific project requirements.\n\n\n\n\n\n### Stages\n\nYou can see from either the vanilla Jenkins pipelines view of the Application Console pipelines view, each template offers a number of pipeline stages. The stages have been configured to be work from the defined `secrets` and `config maps` that have been defined in the Development cluster setup.\n\nThe `Jenkinsfile` is consistent between registration with OpenShift or IKS. The `Dockerfile` has been optimized for `UBI` images, this means the docker images when deployed can run on both OpenShift and IKS.\n\nThe following gives a description of what each stage in the pipeline does. The *Optional* stages can be deleted or ignored if the tool support it is not installed. These stages represent a typical production pipeline flow for a Cloud Native application.\n\n- **Setup** clones the code into the pipeline\n- **Build** runs the build commands for the code\n- **Test**\tvalidates the unit tests for the code\n- **Publish pacts**\t(*optional*) publishes any pact contracts that have been defined\n- **Verify pact** (*optional*) verifies the pact contracts\n- **Sonar scan** (*optional*) runs a sonar code scan of the source code and publishes the results to SonarQube\n- **Verify environment** Validates the OpenShift or IKS environment configuration is valid\n- **Build image** Builds the code into a Docker images and stores it in the IBM Cloud Image registry\n- **Deploy to DEV env**\tDeploys the Docker image tagged version to `dev` namespace using Helm Chart\n- **Health Check** Validates the Health Endpoint of the deployed application\n- **Package Helm Chart** (*optional*) Stores the tagged version of the Helm chart into Artifactory\n- **Trigger CD Pipeline** (*optional*) This is a GitOps stage that will update the build number in designated git repo and trigger ArgoCD for deployment to **test**\n\n\n## Registering Pipelines\n\n\n\n\n\nOnce you become familiar with deploying code into OpenShift or IKS, read up about how you can manage code deployment with `Continuous Deployment` with `Artiactory` and `ArgoCD`\n\n- [Artiact Storage with Artifactory](./ARTIFACTORY.md)\n- [Continuous Deployment with ArgoCD](./ARGOCD.md)\n\nYou can use the [Argo CD Template](https://github.com/ibm-garage-cloud/template-argocd-test) to help define a deployment configuration for `test` and `staging` namespaces.\n\n\n\n","type":"Mdx","contentDigest":"f596ee7506ec23a85830e2fbc48e500c","counter":425,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Continuous Integration with Jenkins","description":"This guide will explain how to use Jenkins to manage your Continuous Integration process"},"exports":{},"rawBody":"---\ntitle: Continuous Integration with Jenkins\ndescription: This guide will explain how to use Jenkins to manage your Continuous Integration process\n---\n\nContinous integration is a software development technique where software is built regularly by a team in an automated fashion.\nThis quote helps explain it:\n\n> Continuous Integration is a software development practice where members of a team integrate their work frequently,\n> usually each person integrates at least daily - leading to multiple integrations per day.\n> Each integration is verified by an automated build (including test) to\n> detect integration errors as quickly as possible. Many teams find that this approach leads to significantly\n> reduced integration problems and allows a team to develop cohesive software more rapidly\n> <cite>– Martin Fowler</cite>\n\n## What is Jenkins\n\nJenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.\nIt is a perfect tool for helping managing continuous integration tasks for a wide range of software component's.\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.\n\nA continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines \"as code\". The definition of a Jenkins Pipeline is typically written into a text file (called a [Jenkinsfile](https://jenkins.io/doc/pipeline/tour/hello-world/)) which in turn is checked into a project’s source control repository.\n\n\n\n### Pipelines\n\nPipelines offer a set of stages or steps that can be chained together to allow a level of software\nautomation. This automation can be tailored to the specific project requirements.\n\n\n\n\n\n### Stages\n\nYou can see from either the vanilla Jenkins pipelines view of the Application Console pipelines view, each template offers a number of pipeline stages. The stages have been configured to be work from the defined `secrets` and `config maps` that have been defined in the Development cluster setup.\n\nThe `Jenkinsfile` is consistent between registration with OpenShift or IKS. The `Dockerfile` has been optimized for `UBI` images, this means the docker images when deployed can run on both OpenShift and IKS.\n\nThe following gives a description of what each stage in the pipeline does. The *Optional* stages can be deleted or ignored if the tool support it is not installed. These stages represent a typical production pipeline flow for a Cloud Native application.\n\n- **Setup** clones the code into the pipeline\n- **Build** runs the build commands for the code\n- **Test**\tvalidates the unit tests for the code\n- **Publish pacts**\t(*optional*) publishes any pact contracts that have been defined\n- **Verify pact** (*optional*) verifies the pact contracts\n- **Sonar scan** (*optional*) runs a sonar code scan of the source code and publishes the results to SonarQube\n- **Verify environment** Validates the OpenShift or IKS environment configuration is valid\n- **Build image** Builds the code into a Docker images and stores it in the IBM Cloud Image registry\n- **Deploy to DEV env**\tDeploys the Docker image tagged version to `dev` namespace using Helm Chart\n- **Health Check** Validates the Health Endpoint of the deployed application\n- **Package Helm Chart** (*optional*) Stores the tagged version of the Helm chart into Artifactory\n- **Trigger CD Pipeline** (*optional*) This is a GitOps stage that will update the build number in designated git repo and trigger ArgoCD for deployment to **test**\n\n\n## Registering Pipelines\n\n\n\n\n\nOnce you become familiar with deploying code into OpenShift or IKS, read up about how you can manage code deployment with `Continuous Deployment` with `Artiactory` and `ArgoCD`\n\n- [Artiact Storage with Artifactory](./ARTIFACTORY.md)\n- [Continuous Deployment with ArgoCD](./ARGOCD.md)\n\nYou can use the [Argo CD Template](https://github.com/ibm-garage-cloud/template-argocd-test) to help define a deployment configuration for `test` and `staging` namespaces.\n\n\n\n","fileAbsolutePath":"/Users/bwoolf/dev/git/ibm-garage-cloud/ibm-garage-developer-guide/src/pages/guides/continuous-integration/index.mdx"}}}}